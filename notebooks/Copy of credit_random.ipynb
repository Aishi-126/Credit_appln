{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1nmyc5O5kkZXVHzhH7U1qJWyeiSG-9FhM","timestamp":1711395968056}],"authorship_tag":"ABX9TyN9jJ2EjBY7lYDz21K2T+T/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import files\n","files.upload()"],"metadata":{"id":"LqjKmGVRodom","outputId":"3c6cfade-b6e6-4680-f298-9280e2f60eb7","colab":{"base_uri":"https://localhost:8080/","height":56}},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-fe673f09-3252-4eab-9b79-8d8f637ac9c8\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-fe673f09-3252-4eab-9b79-8d8f637ac9c8\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}}]},{"cell_type":"code","source":["from google.colab import files\n","files.upload()"],"metadata":{"id":"FkizSEge-aG0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from scipy import stats as st\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import precision_recall_curve\n","from sklearn.preprocessing import label_binarize\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.preprocessing import PowerTransformer\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.model_selection import cross_val_score\n","from sklearn.feature_selection import RFE\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.calibration import CalibratedClassifierCV, CalibrationDisplay\n","from xgboost import XGBClassifier\n","from lightgbm import LGBMClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.neighbors import KNeighborsClassifier\n","import optuna\n","import json\n","from optuna.visualization import plot_optimization_history\n","from optuna.visualization import plot_parallel_coordinate\n","from optuna.visualization import plot_param_importances\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","%matplotlib inline\n","\n","sns.set_style(\"darkgrid\")\n"],"metadata":{"id":"ITy2gLo_cpaa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import warnings\n","warnings.filterwarnings(\"ignore\")"],"metadata":{"id":"zXSHjuShcxZx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Data Summary¶**\n","If you want to work on cleaned dataset you can directly move to data visualization section, data summary and cleaning section deals with messy and uncleaned data from which after through preprocessing Loan Credit Score Classification Problem dataset is created."],"metadata":{"id":"oVepaQbSc018"}},{"cell_type":"code","source":["train=pd.read_csv('train.csv',encoding='latin')\n","test=pd.read_csv('test.csv',encoding='latin')"],"metadata":{"id":"VoVvANNXc6jd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train.head()"],"metadata":{"id":"07JQtRFPdBxw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train.info()"],"metadata":{"id":"9WmtQzGJdEah"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train.describe().T"],"metadata":{"id":"aBEEzUR0dLhG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["100*train.isnull().sum()"],"metadata":{"id":"xz9e55FBdPGs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Data Cleaning¶**\n","On closely observing data, the conslusion is data contains 8 consecutive months data for 12500 customers, while much information remains same for 8 months data like **Name,Annual_Income, Num_Bank_Accounts, Interest_Rate,Num_of_Loan, Outstanding_Debt**,some variables changes evry monthly **Amount_invested_monthly, Monthly_Balance** while there are some variables that dependent on previous values and increments like **Num_of_Delayed_Payment, Num_Credit_Inquiries, Credit_History_Age.**\n","\n","There are also outliers and wrong information present like Payment_Behaviour==\"!@9#%8\", negative values for ***Num_Bank_Accounts, Num_of_Loan*** and extremely high value for Amount_invested_monthly etc.\n","\n","For variables where infromation remain same throughout 8 months, we will caluate mode and replace null and wrong values with mode.\n","\n","For variables that vary monthly, we will replace outliers and null values using the mode caluated for each customer_id.\n","\n","For variables that increments, we will use past and future values to impute missing values using forward and backward fill.\n","There are many variables that should be numerical type but present as object type like **Num_of_Loan, Num_of_Delayed_Payment, Changed_Credit_Limit, Outstanding_Debt, Amount_invested_monthly**. These variables contain mixed types some instances as int/float while others as string.\n","**ID, Customer_ID, Month, Name, SSN, Occupation, Type_of_Loan** will be dropped as they are not useful for classification task."],"metadata":{"id":"h1-uj2XrdeRx"}},{"cell_type":"markdown","source":["Categorical variable"],"metadata":{"id":"_cVRLiHhfKsL"}},{"cell_type":"code","source":["data=train.copy()"],"metadata":{"id":"AHAfAYrodV71"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Categorical Variables\n","col=[\"Credit_Mix\", \"Payment_of_Min_Amount\", \"Payment_Behaviour\", \"Type_of_Loan\"]"],"metadata":{"id":"GSthXTX0fO7n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data[\"Credit_Mix\"].value_counts()"],"metadata":{"id":"ZEtbWB0IfWK-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["index=data[data[\"Credit_Mix\"]==\"_\"].index\n","data.loc[index,\"Credit_Mix\"]=np.nan\n","df=data[-data[\"Credit_Mix\"].isna()]\n","ser=df.groupby(\"Customer_ID\")[\"Credit_Mix\"].agg(st.mode).apply(lambda x:x[0][0])\n","data.drop(\"Credit_Mix\",axis=1,inplace=True)\n","data=pd.merge(left=data,right=ser,how=\"left\",left_on=\"Customer_ID\",right_index=True)"],"metadata":{"id":"raSvzGWJfaMl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data[\"Payment_Behaviour\"].value_counts()"],"metadata":{"id":"4SsfxrcXfd6q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["index=data[data[\"Payment_Behaviour\"]==\"!@9#%8\"].index\n","data.loc[index,\"Payment_Behaviour\"]=np.nan\n","df=data[-data[\"Payment_Behaviour\"].isna()]\n","ser=data.groupby(\"Customer_ID\")[\"Payment_Behaviour\"].agg(st.mode).apply(lambda x:x[0][0])\n","data.drop(\"Payment_Behaviour\",axis=1,inplace=True)\n","data=pd.merge(left=data,right=ser,how=\"left\",left_on=\"Customer_ID\",right_index=True)"],"metadata":{"id":"F2Hgt36vfjHG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data[\"Payment_of_Min_Amount\"].value_counts()"],"metadata":{"id":"YO4nN3NyfqZz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Numerical Variable**"],"metadata":{"id":"2CiOa9fufzVs"}},{"cell_type":"code","source":["'''Features that should be of numerical type but are present as categorical\n","   variable(object type), we will convert them to numerical type.These variable\n","   contain mix type, for example Monthly_Balance variable contain float type for\n","   index 0:98303 and string type from index 98304:99999'''\n","\n","cols=['Age','Annual_Income','Num_of_Loan','Num_of_Delayed_Payment','Changed_Credit_Limit',\n","      'Outstanding_Debt','Amount_invested_monthly','Monthly_Balance']\n","\n","for col in cols:\n","    data[col]=data[col].apply(lambda x: x if x is np.nan or not isinstance(x, str)\n","                        else x.replace(\"_\",\"\")).replace(\"\",np.nan)\n","    data[col]=data[col].astype(np.float64)"],"metadata":{"id":"IU4ug8g0fs8z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cols=[\"Age\", \"Annual_Income\", \"Num_Bank_Accounts\",\"Num_Credit_Card\", \"Interest_Rate\",\n","      \"Num_of_Loan\", \"Monthly_Inhand_Salary\",\"Changed_Credit_Limit\",\"Outstanding_Debt\",\n","      \"Total_EMI_per_month\"]\n","\n","for col in cols:\n","    index=data[data[col]<0].index\n","    data.loc[index,col]=np.nan\n","    df=data[-data[col].isna()]\n","    ser=df.groupby(\"Customer_ID\")[col].agg(st.mode).apply(lambda x:x[0][0])\n","    data.drop(col,axis=1,inplace=True)\n","    data=pd.merge(left=data,right=ser,how=\"left\",left_on=\"Customer_ID\",right_index=True)"],"metadata":{"id":"Bah4FHzqf5LD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''These features can best imputed by same feature values present in customer record for\n","   different month,therefore we will use that customer record for imputating missing\n","   value using ffill and bfill'''\n","\n","inter=data[\"Credit_History_Age\"].str.split(\" \")\n","data[\"Credit_History_Age\"]=inter.apply(lambda x:x if x is np.nan else int(x[0])*12+int(x[3]))\n","\n","cols=['Num_of_Delayed_Payment', 'Num_Credit_Inquiries',\"Credit_History_Age\",\n","      \"Delay_from_due_date\"]\n","for col in cols:\n","    if col in ['Num_of_Delayed_Payment', 'Num_Credit_Inquiries']:\n","        index2=data[(data[col]>=30)].index\n","        data.loc[index2,col]=np.nan\n","    index1=data[(data[col]<0)].index\n","    data.loc[index1,col]=np.nan\n","    data[col]=data.groupby(\"Customer_ID\")[col].transform(lambda x:x.ffill())\n","    data[col]=data.groupby(\"Customer_ID\")[col].transform(lambda x:x.bfill())"],"metadata":{"id":"qyRiJpk0gzwr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for col in ['Amount_invested_monthly', 'Monthly_Balance']:\n","    if col in ['Amount_invested_monthly']:\n","        index2=data[(data[col]==10000.0)].index\n","        data.loc[index2,col]=np.nan\n","    index1=data[(data[col]<0)].index\n","    data.loc[index1,col]=np.nan\n","    ser=data.groupby(\"Customer_ID\")[col].transform(lambda x:x.median())\n","    data[col].fillna(ser,inplace=True)"],"metadata":{"id":"-gWoPyuhg6Be"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data.describe().T"],"metadata":{"id":"M5ozloOgg9pJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Redundant variable will be dropped\n","\n","drop=[\"ID\", \"Customer_ID\", \"Month\",\"Name\", \"SSN\", \"Occupation\",\"Type_of_Loan\"]\n","data.drop(columns=drop,axis=1,inplace=True)"],"metadata":{"id":"qQQsAYrGg_p7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data.dropna(axis=0, inplace=True)"],"metadata":{"id":"JrQr5OxthDpp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data.to_csv(\"Score.csv\",index=False)"],"metadata":{"id":"aL39ER1ihFaG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Data Visualization**"],"metadata":{"id":"kKI-8D-nhH6m"}},{"cell_type":"code","source":["data=pd.read_csv(\"/kaggle/input/processed-data-credit-score/Score.csv\")"],"metadata":{"id":"FEvNmu8qhLGr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Clean Data Features Description**\n","**Age:** Represents the age of the person\n","\n","**Annual_Income:** Represents the annual income of the person\n","\n","**Monthly_Inhand_Salary:** Represents the monthly base salary of a person\n","\n","**Num_Bank_Accounts:**Represents the number of bank accounts a person holds\n","\n","**Num_Credit_Card:** Represents the number of other credit cards held by a person\n","\n","**Interest_Rate:** Represents the interest rate on credit card\n","\n","**Num_of_Loan:** Represents the number of loans taken from the bank\n","\n","**Delay_from_due_date:** Represents the average number of days delayed from the payment date\n","\n","**Num_of_Delayed_Payment:** Represents the average number of payments delayed by a person\n","\n","**Changed_Credit_Limit:** Represents the percentage change in credit card limit\n","\n","**Num_Credit_Inquiries:** Represents the number of credit card inquiries\n","\n","**Credit_Mix:** Represents the classification of the mix of credits\n","\n","**Outstanding_Debt:** Represents the remaining debt to be paid (in USD)\n","\n","**Credit_Utilization_Ratio:** Represents the utilization ratio of credit card\n","\n","**Credit_History_Age:** Represents the age of credit history of the person\n","\n","**Payment_of_Min_Amount:** Represents whether only the minimum amount was paid by the person\n","\n","**Total_EMI_per_month:** Represents the monthly EMI payments (in USD)\n","\n","**Amount_invested_monthly:** Represents the monthly amount invested by the customer (in USD)\n","\n","**Monthly_Balance:** Represents the monthly balance amount of the customer (in USD)\n","\n","**Credit_Score:** Represents the bracket of credit score (Poor, Standard, Good)"],"metadata":{"id":"AJn6SWsPhPxB"}},{"cell_type":"code","source":["X=data.drop(\"Credit_Score\",axis=1)\n","y=data[\"Credit_Score\"]\n","\n","numeric=X.select_dtypes(exclude=\"object\").columns\n","categorical=['Payment_of_Min_Amount', 'Credit_Mix']\n","\n","low_cardinality=[col for col in numeric if data[col].nunique()<=30]\n","high_cardinality=[col for col in numeric if data[col].nunique()>30]"],"metadata":{"id":"5DEN7vMT_QN3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ser=data[\"Credit_Score\"].value_counts()\n","plt.pie(x=ser.values, labels=ser.index, autopct=\"%0.2f%%\", radius=2);\n","plt.savefig(\"image1.png\")"],"metadata":{"id":"SwNzav3P_ZCY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**There is unequal class distribution in target variable,but the difference ratio is not very high. we will test cost-sensitive learning on the dataset.**"],"metadata":{"id":"L7dSMvI9_dAv"}},{"cell_type":"code","source":["rows=[len(high_cardinality)//2 if len(high_cardinality)%2==0 else len(high_cardinality)//2+1]\n","fig,axes=plt.subplots(rows[0],2,figsize=(10,30))\n","\n","ax=axes.flatten()\n","for i,col in enumerate(high_cardinality):\n","    sns.histplot(data=data,x=col,hue=\"Credit_Score\",ax=ax[i],multiple=\"stack\");\n","\n","plt.tight_layout()\n","plt.savefig(\"image2.png\")"],"metadata":{"id":"y8a11npt_f-Y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Outstanding_Debt,Interest_Rate,Delay_from_due_date** as these variables value increases, the proportion of Bad Credit_Score instances increases substantially, while Standard and Good Credit_Score instances proportion become meagre.\n","\n","On the other hand increase in **Credit_History_Age, Age** reults in decrease of Bad Credit_Score instances, jump in Standard and Good Credit_Score instance.\n","Interestingly credit_utilization_ratio seems to seems to have same distribution for all categories of credit score.\n","\n","The distribution of many features have non-gaussian distribution and largely different scales, therefore we will tranform feature variables."],"metadata":{"id":"5rDTml8d_lp9"}},{"cell_type":"code","source":["cols=[\"Outstanding_Debt\", \"Interest_Rate\", \"Delay_from_due_date\", \"Credit_History_Age\"]\n","vals=[\"Good\",\"Standard\",\"Poor\"]\n","colors=[\"blue\",\"orange\",\"green\"]\n","\n","fig,axes=plt.subplots(len(cols),3,figsize=(15,25))\n","\n","for i,col in enumerate(cols):\n","    for j,(val,color) in enumerate(zip(vals,colors)):\n","        ax=axes[i,j]\n","        inter=data[data[\"Credit_Score\"]==val]\n","        sns.histplot(data=inter,x=col,ax=ax,color=color,kde=True);\n","        ax.set_title(f\"{val} distribution for {col}\")\n","\n","plt.tight_layout()\n","plt.savefig(\"image3.png\")\n"],"metadata":{"id":"W6Ey-HO-_uK9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(8, 6))\n","arr=np.ones_like(data[high_cardinality].corr())\n","mask=np.triu(arr)\n","sns.heatmap(data[high_cardinality].corr(), cbar=False, annot=True, fmt=\".2g\", mask=mask);\n","plt.savefig(\"image4.png\")"],"metadata":{"id":"eP3Rip-l_3k5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","Many variable have strong correlation with others,for example **Num_of_Delayed_Payment** has strong positive correlation with interest_rate charged(0.57), outstanding_debt(0.50), delay_from_due_date (0.54), Num_Credit_Inquiries (0.50) and strong negative correlation with Credit_History_Age (-0.49) and Monthly_Inhand_Salary(-0.28).\n","\n","**A person who has taken large sum of money at high interest rate with less salary, financial discipline and savings are more likely to have high no of delayed payments, looking for more credit to pay off loans, ending up with high interest rate and large debt.**\n","\n","**Credit_History_Age** has strong negative correlation with Num_of_Delayed_Payment, Num_Credit_Inquiries, Interest_Rate, Outstanding_Debt."],"metadata":{"id":"-kRHoWCp_8GO"}},{"cell_type":"code","source":["fig,axes=plt.subplots(2,2,figsize=(10,12))\n","\n","for i,col in enumerate(categorical[:-1]):\n","    ax=axes[i,0]\n","    sns.countplot(x=data[col],hue=data[\"Credit_Score\"],ax=ax)\n","    ax.set_xticklabels(labels=data[col].unique(),rotation=90)\n","    ax.legend()\n","\n","    ax=axes[i,1]\n","    sns.violinplot(x=data[col],hue=data[\"Credit_Score\"],y=data[\"Outstanding_Debt\"],ax=ax)\n","    ax.set_xticklabels(labels=data[col].unique(),rotation=90)\n","    ax.legend()\n","\n","plt.tight_layout()\n","plt.savefig(\"image5.png\")"],"metadata":{"id":"quDXBC8zADjy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can see **Credit_Mix** and **Payment_of_Min_Amount** influences the categories of Credit_Score\n","\n","If someone has made Payment_of_Min_Amount, poor score have higher outstanding debt than standard and good debt, while if someone has not made Payment_of_Min_Amount then outstanding debt have no impact on credit score."],"metadata":{"id":"8nP8NaodAKof"}},{"cell_type":"code","source":["fig,axes=plt.subplots(5,figsize=(10,20))\n","\n","for i,col in enumerate(low_cardinality):\n","\n","    ax=axes[i]\n","    sns.violinplot(x=data[col],y=data[\"Credit_Score\"],ax=ax);\n","    ax.set_xticklabels(labels=data[col].unique(),rotation=90)\n","\n","plt.tight_layout()\n","plt.savefig(\"image6.png\")\n"],"metadata":{"id":"pbANpb9sAIGh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["As the variables **Num_of_Delayed_Payment**,** Num_Credit_Inquiries**, **Num_Bank_Accounts, Num_Credit_Card, Num_of_Loan** values increases the proportion of poor credit scores increases, while good and standard credit scores instances were quite less.\n","\n","**Num_of_Delayed_Payment** variable having the most visible effect."],"metadata":{"id":"XN_jdY35AYpc"}},{"cell_type":"code","source":["from itertools import product\n","arr1=[\"Credit_History_Age\",\"Monthly_Inhand_Salary\"]\n","arr2=[\"Outstanding_Debt\",\"Interest_Rate\",\"Delay_from_due_date\"]\n","\n","pairs=list(product(arr1,arr2))\n","\n","fig,axes=plt.subplots(len(pairs),3,figsize=(15,30))\n","\n","for i,(x,y) in enumerate(pairs):\n","    colors=[\"blue\",\"orange\",\"green\"]\n","    vals=[\"Good\",\"Standard\",\"Poor\"]\n","    for j,(color,val) in enumerate(zip(colors,vals)):\n","        ax=axes[i,j]\n","        inter=data[data[\"Credit_Score\"]==val]\n","        sns.histplot(x=x,y=y,data=inter,color=color,ax=ax);\n","\n","plt.tight_layout()\n","plt.savefig(\"image7.png\")"],"metadata":{"id":"qqFMbsV2AVAq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Theses charts shows density distribution of credit scores categories using bivariate analysis.\n","\n","**Overlapping instances zones are places where instances are mostly misclassified, seeing the data ensemble based learning methods will be best, while linear models will be ineffective because of presence of complex non-linear relationship.SVM will be time consuming because of large dataset size, overlapping of instances.**"],"metadata":{"id":"3NKWMiSrAsFw"}},{"cell_type":"markdown","source":["**Data Preprocessing**"],"metadata":{"id":"xGN1xRP-A0aI"}},{"cell_type":"code","source":["#label encoding target variable\n","label=LabelEncoder()\n","label.fit(data[\"Credit_Score\"])\n","y=label.transform(data[\"Credit_Score\"])\n","\n","#transforming and scaling numerical variable\n","transformer=PowerTransformer()\n","transformer.fit(data[high_cardinality])\n","numeric=transformer.transform(data[high_cardinality])\n","\n","#one hot encoding\n","encoding=OneHotEncoder(drop=\"first\")\n","encoding.fit(data[categorical])\n","one_hot=encoding.transform(data[categorical]).toarray()\n","\n","#ordinal variables\n","ordinal=data[low_cardinality].values\n","\n","#Feature array\n","X=np.concatenate([numeric,one_hot,ordinal],axis=1)"],"metadata":{"id":"bCzEkMbzApwz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Algorithm Spot Checking**"],"metadata":{"id":"r9COA3t9BDyl"}},{"cell_type":"code","source":["def get_models():\n","    names,models=[],[]\n","\n","    models.append(RandomForestClassifier(random_state=42,n_jobs=-1))\n","    names.append(\"RandomForestClassifier\")\n","\n","    models.append(XGBClassifier(random_state=42,n_jobs=-1))\n","    names.append(\"XGBClassifier\")\n","\n","    models.append(LGBMClassifier(random_state=42,n_jobs=-1))\n","    names.append(\"LGBMClassifier\")\n","\n","    return names,models"],"metadata":{"id":"iMouI2gYBG-S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["names,models=get_models()\n","fig,axes=plt.subplots(3,2,figsize=(12,15))\n","result={}\n","\n","for i in range(len(models)):\n","    scores=[]\n","    importance=[]\n","    probability=[]\n","\n","    for train_idx,val_idx in StratifiedKFold(n_splits=5).split(X,y):\n","        model=models[i].fit(X[train_idx,:],y[train_idx])\n","        y_pred=model.predict(X[val_idx,:])\n","        y_true=y[val_idx]\n","        score=f1_score(y_true,y_pred,average='macro')\n","\n","        scores.append(score)\n","        importance.append(model.feature_importances_)\n","        probability.append(model.predict_proba(X[val_idx,:]))\n","\n","    ax=axes[i,0]\n","    frame=pd.DataFrame(importance)\n","    result_p=pd.melt(frame,value_vars=frame.columns)\n","    sns.barplot(x=\"variable\",y=\"value\",data=result_p,ax=ax);\n","    ax.set_title(f\"{names[i]} model feature importance\")\n","\n","    ax=axes[i,1]\n","    y_true=label_binarize(y,classes=range(len(label.classes_)))\n","    y_proba=np.concatenate([probability[j] for j in range(len(probability))])\n","    for k in range(len(label.classes_)):\n","        precision,recall,thresh=precision_recall_curve(y_true[:,k],y_proba[:,k])\n","        sns.scatterplot(recall, precision, alpha=0.95,ax=ax,label=label.classes_[k])\n","    ax.legend()\n","    ax.set_title(f\"{names[i]} model precision recall curve\")\n","\n","    plt.tight_layout()\n","    result[names[i]]=scores\n","\n","plt.savefig(\"image8.png\")"],"metadata":{"id":"Sy3IZZToBXBQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["While the precision recall curve is nearly same for all three classifier, different features are hold diffrenet significance for models, with xgboost model feature importance quite from other model. This signifies that model are diffrent and using their values in an ensemble or stacking might increase performance. Also lgbm model performed better than xgboost and random forest classifier.\n","\n","The precision recall curve also tells us that good credit score is misclssified more than standard and poor credit score class. Standard Credit Score class is misclassified least across all three models.\n","\n","The models are performing better on standard instances, underperforming on good and poor instances this can be due to class imbalance. Therefore we can use data sampling technique specially those that increase the instances of classes in borderline or overlapping area."],"metadata":{"id":"FgkRu0OIBgOg"}},{"cell_type":"code","source":["plt.figure(figsize=(10,8))\n","frame=pd.DataFrame(result)\n","result_p=pd.melt(frame,value_vars=frame.columns)\n","sns.violinplot(x=\"variable\",y=\"value\",data=result_p);\n","plt.savefig(\"image9.png\")"],"metadata":{"id":"42mfb9JvBc1k"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**LGBMClassifier**"],"metadata":{"id":"SFiU0TOWBvWn"}},{"cell_type":"code","source":["def objective(trial):\n","\n","    params={\"n_estimators\":trial.suggest_int(\"n_estimators\",100,400),\n","            \"max_depth\":trial.suggest_int(\"max_depth\",3,8),\n","            \"learning_rate\":trial.suggest_float(\"learning_rate\", 0.01, 0.1,log=True),\n","            \"subsample\":trial.suggest_float(\"subsample\",0.2,0.8),\n","            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\",0.2,0.8),\n","            \"reg_lambda\":trial.suggest_float(\"reg_lambda\", 0.01, 0.1,log=True)}\n","\n","    model=LGBMClassifier(**params,random_state=42,n_jobs=-1)\n","    cv=StratifiedKFold(n_splits=5)\n","    scores=cross_val_score(model,X,y,scoring=\"f1_macro\",cv=cv,n_jobs=-1)\n","    trial.set_user_attr(\"f1_macro\", scores.mean())\n","\n","    return scores.mean()"],"metadata":{"id":"-em5MXWRBsH0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["study = optuna.create_study(study_name=\"Hyperparameter optimization\",direction=\"maximize\",\n","                            sampler=optuna.samplers.TPESampler(seed=42))\n","study.optimize(objective, n_trials=20,show_progress_bar=True)"],"metadata":{"id":"1Mntc7ifB1a-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"Best value: {study.best_trial.value}\")\n","print(f\"Best hyperparameters:\\n {json.dumps(study.best_trial.params, indent=2)}\")"],"metadata":{"id":"Oo3xlI2zB62a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_optimization_history(study)"],"metadata":{"id":"xoD63gPvB9Qs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_param_importances(study)\n","plt.savefig(\"image10.png\")"],"metadata":{"id":"ZZ3C69Y7CA2S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["params=[\"n_estimators\",\"max_depth\",\"learning_rate\",\"colsample_bytree\"]\n","plot_parallel_coordinate(study,params=params)\n","plt.savefig(\"image11.png\")"],"metadata":{"id":"eSc14JafCIR-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**XGBClassifier**"],"metadata":{"id":"B0BMznfBCM3G"}},{"cell_type":"code","source":["def objective(trial):\n","\n","    params={\"n_estimators\":trial.suggest_int(\"n_estimators\",100,400),\n","            \"max_depth\":trial.suggest_int(\"max_depth\",3,8),\n","            \"learning_rate\":trial.suggest_float(\"learning_rate\", 0.01, 0.1,log=True),\n","            \"subsample\":trial.suggest_float(\"subsample\",0.2,0.8),\n","            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\",0.2,0.8),\n","            \"reg_lambda\":trial.suggest_float(\"reg_lambda\", 0.01, 0.1,log=True)}\n","\n","    model=XGBClassifier(**params,random_state=42,n_jobs=-1)\n","    cv=StratifiedKFold(n_splits=5)\n","    scores=cross_val_score(model,X,y,scoring=\"f1_macro\",cv=cv,n_jobs=-1)\n","    trial.set_user_attr(\"f1_macro\", scores.mean())\n","\n","    return scores.mean()"],"metadata":{"id":"0R2L3wEDCKoa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["study = optuna.create_study(study_name=\"Hyperparameter optimization\",direction=\"maximize\",\n","                            sampler=optuna.samplers.TPESampler(seed=42))\n","study.optimize(objective, n_trials=20,show_progress_bar=True)"],"metadata":{"id":"Cvy-rHvkCUuy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"Best value: {study.best_trial.value}\")\n","print(f\"Best hyperparameters:\\n {json.dumps(study.best_trial.params, indent=2)}\")"],"metadata":{"id":"L_XEwQMcCaU8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_optimization_history(study)"],"metadata":{"id":"nX6CQal7Chyl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_param_importances(study)\n","plt.savefig(\"image12.png\")"],"metadata":{"id":"PC5QNkWVCk7o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["params=[\"n_estimators\",\"max_depth\",\"colsample_bytree\"]\n","plot_parallel_coordinate(study,params=params)\n","plt.savefig(\"image13.png\")"],"metadata":{"id":"Yldg43rACmn-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**RandomForestClassifer**"],"metadata":{"id":"UEV3qUgFCoxH"}},{"cell_type":"code","source":["def objective(trial):\n","\n","    params={\"n_estimators\":trial.suggest_int(\"n_estimators\",100,400),\n","            \"max_depth\":trial.suggest_int(\"max_depth\",3,8),\n","            \"max_samples\":trial.suggest_float(\"max_samples\",0.2,0.8),\n","            \"min_samples_split\": trial.suggest_int(\"min_samples_split\",2,20),\n","            \"max_features\":trial.suggest_categorical(\"max_features\", [\"auto\", \"sqrt\", \"log2\"])}\n","\n","    model=RandomForestClassifier(**params,random_state=42,n_jobs=-1)\n","    cv=StratifiedKFold(n_splits=5)\n","    scores=cross_val_score(model,X,y,scoring=\"f1_macro\",cv=cv,n_jobs=-1)\n","    trial.set_user_attr(\"f1_macro\", scores.mean())\n","\n","    return scores.mean()"],"metadata":{"id":"wC2nS8efCsv-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["study = optuna.create_study(study_name=\"Hyperparameter optimization\",direction=\"maximize\",\n","                            sampler=optuna.samplers.TPESampler(seed=42))\n","study.optimize(objective, n_trials=20,show_progress_bar=True)"],"metadata":{"id":"7OHCJsCHCwD2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"Best value: {study.best_trial.value}\")\n","print(f\"Best hyperparameters:\\n {json.dumps(study.best_trial.params, indent=2)}\")"],"metadata":{"id":"kvfrtp0OCz3Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_optimization_history(study)"],"metadata":{"id":"o1as25ANC21E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_param_importances(study)\n","plt.savefig(\"image14.png\")"],"metadata":{"id":"46Ft6zNaC5fA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["params=[\"max_depth\", \"max_samples\", \"min_samples_split\"]\n","plot_parallel_coordinate(study,params=params)\n","plt.savefig(\"image15.png\")"],"metadata":{"id":"uuYGYuyUC8sB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Ensemble of Models**"],"metadata":{"id":"PjwCiHYwC-wF"}},{"cell_type":"code","source":["lgbm_params={\"n_estimators\": 319,\n","             \"max_depth\": 5,\n","             \"learning_rate\": 0.01007506187129231,\n","             \"subsample\": 0.7243746196920224,\n","             \"colsample_bytree\": 0.6043128820104816,\n","             \"reg_lambda\": 0.010068213652019799 }\n","\n","xgb_params={\"n_estimators\": 319,\n","            \"max_depth\": 5,\n","            \"learning_rate\": 0.010320226911021985,\n","            \"subsample\": 0.41644521272647506,\n","            \"colsample_bytree\": 0.6465159042623695,\n","            \"reg_lambda\": 0.04479410490748427 }\n","\n","rf_params={\"n_estimators\": 212,\n","           \"max_depth\": 8,\n","           \"max_samples\": 0.6391963650868431,\n","           \"min_samples_split\": 13,\n","           \"max_features\": \"auto\"}"],"metadata":{"id":"gqY4BhvHDC2S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["models={\"LGBMClassifier\":LGBMClassifier(**lgbm_params,random_state=42,n_jobs=-1),\n","        \"XGBClassifier\":XGBClassifier(**xgb_params,random_state=42,n_jobs=-1),\n","        \"RandomForestClassifier\":RandomForestClassifier(**rf_params,random_state=42,n_jobs=-1)}"],"metadata":{"id":"jq-7-GXlDJJP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["probability=dict(zip(models.keys(),[[] for _ in range(len(models.keys()))]))\n","\n","for train_idx,val_idx in StratifiedKFold(n_splits=5).split(X,y):\n","    X_train,y_train=X[train_idx,:],y[train_idx]\n","    X_val,y_val=X[val_idx,:],y[val_idx]\n","    for name,model in models.items():\n","        algo=model.fit(X_train,y_train)\n","        y_proba=algo.predict_proba(X[val_idx,:])\n","        probability[name].append(algo.predict_proba(X[val_idx,:]))"],"metadata":{"id":"AKORXRwdDL00"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inter=probability.copy()"],"metadata":{"id":"3U_3B5u7DPbj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_true=label_binarize(y,classes=range(len(label.classes_)))\n","probas=dict(zip(models.keys(),[[] for _ in range(len(models.keys()))]))\n","for name in models.keys():\n","    proba=np.concatenate([probability[name][i] for i in range(len(probability[name]))])\n","    probas[name].append(proba)"],"metadata":{"id":"1cYh9JBBDTEi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig,axes=plt.subplots(3,1,figsize=(15,15))\n","ax=axes.flatten()\n","\n","for i,classes in enumerate(list(label.classes_)):\n","    ax[i].set_title(f\"Calibration Curve for {classes}\",fontweight=\"bold\")\n","    for name,prediction in probas.items():\n","        y_real=y_true[:,i]\n","        y_prob=probas[name][0][:,i]\n","        CalibrationDisplay.from_predictions(y_real,y_prob,n_bins=10, strategy='quantile',ax=ax[i],name=name);\n","\n","plt.tight_layout()\n","plt.savefig(\"image16.png\")"],"metadata":{"id":"x8F8ezntDWz2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**The probabilities predicted by the models for each class in target variable is well calibrated. Therefore there is no need to calibrate the predicted probabailities.**"],"metadata":{"id":"8zkQ70YHDcFV"}},{"cell_type":"code","source":["probas[\"Average_Models\"]=[np.add(probas[\"LGBMClassifier\"][0],probas[\"XGBClassifier\"][0])]\n","probas[\"Average_Models\"]=[np.add(probas[\"Average_Models\"][0],probas[\"RandomForestClassifier\"][0])/3]"],"metadata":{"id":"9n2ARnDzDjX8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(15,15))\n","axes=plt.subplot(1,1,1)\n","\n","for i,classes in enumerate(list(label.classes_)):\n","    y_real=y_true[:,i]\n","    y_prob=probas[\"Average_Models\"][0][:,i]\n","    CalibrationDisplay.from_predictions(y_real,y_prob,n_bins=10, strategy='quantile',name=classes,ax=axes);\n","plt.savefig(\"image17.png\")"],"metadata":{"id":"PntFgoX1DnRY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for models in probas.keys():\n","    sol=np.argmax(probas[models][0],axis=1)\n","    score=f1_score(y,sol,average=\"macro\")\n","    print(f\"\\n{models} f1 score is: {score}\")"],"metadata":{"id":"jbWsEf_RDqMu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**The ensemble of model performed better than individual model, we can also try weights ensemble and stacking. Plus data oversampling of minority instances classes and undersampling of overlapping instances using imblearn library.**"],"metadata":{"id":"fBn-q1DzDtAC"}},{"cell_type":"code","source":["plt.figure(figsize=(10,8))\n","sns.heatmap(confusion_matrix(y,sol),annot=True,cbar=False,xticklabels=label.classes_,yticklabels=label.classes_,cmap=\"Blues\");\n","plt.savefig(\"image18.png\")"],"metadata":{"id":"Zy304pZUDwsv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(classification_report(y,sol))"],"metadata":{"id":"MBRZj5-RD1FO"},"execution_count":null,"outputs":[]}]}